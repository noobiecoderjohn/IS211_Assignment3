import argparse
import csv
import re
from collections import Counter
from datetime import datetime
import requests

def download_log_file(log_url):
    response = requests.get(log_url)
    if response.status_code == 200:
        with open("weblog.csv", "wb") as log_file:
            log_file.write(response.content)

def process_log_file(log_filename):
    image_requests = []
    browser_counts = Counter()
    hour_counts = Counter()
    image_pattern = re.compile(r'\.(jpg|jpeg|png|gif)$', re.IGNORECASE)

    with open(log_filename, newline='') as log_csv:
        csv_reader = csv.reader(log_csv)
        for row in csv_reader:
            path, datetime_accessed, user_agent = row
            if image_pattern.search(path):
                image_requests.append(row)
            browser_match = re.search(r'(Firefox|Chrome|Safari|MSIE)', user_agent)
            if browser_match:
                browser_counts[browser_match.group()] += 1
            access_time = datetime.strptime(datetime_accessed, '%m/%d/%Y %H:%M:%S')
            hour_counts[access_time.hour] += 1

    total_requests = len(image_requests) + sum(browser_counts.values())
    image_percentage = (len(image_requests) / total_requests) * 100
    print(f"Image requests account for {image_percentage:.1f}% of all requests")

    most_popular_browser = browser_counts.most_common(1)[0][0]
    print(f"The most popular browser is {most_popular_browser}")

    print("\nHits by Hour:")
    for hour, hits in sorted(hour_counts.items()):
        print(f"Hour {hour:02} has {hits} hits")

def main(log_url, log_filename):
    download_log_file(log_url, log_filename)
    process_log_file(log_filename)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--url", help="URL of the log file", type=str, required=True)
    parser.add_argument("--filename", help="Filename to save the log file", type=str, default="weblog.csv")
    args = parser.parse_args()
    main(args.url, args.filename)
